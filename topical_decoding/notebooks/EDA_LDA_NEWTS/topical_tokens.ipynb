{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore topical tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.evaluation_utils import get_topic_words, get_topic_tokens\n",
    "from utils.read_and_load_utils import load_lda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the LDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-21 12:17:50,310 - INFO - Data directory found at /Users/joschka/Documents/0_Studium/0_ML_Master/0_current_lectures/NLP_practical_project/local_topical_summarization/data.\n",
      "2024-04-21 12:17:50,310 - INFO - loading LdaModel object from /Users/joschka/Documents/0_Studium/0_ML_Master/0_current_lectures/NLP_practical_project/local_topical_summarization/data/LDA_250/lda.model\n",
      "2024-04-21 12:17:50,426 - INFO - loading id2word recursively from /Users/joschka/Documents/0_Studium/0_ML_Master/0_current_lectures/NLP_practical_project/local_topical_summarization/data/LDA_250/lda.model.id2word.* with mmap=r\n",
      "2024-04-21 12:17:50,426 - INFO - loading expElogbeta from /Users/joschka/Documents/0_Studium/0_ML_Master/0_current_lectures/NLP_practical_project/local_topical_summarization/data/LDA_250/lda.model.expElogbeta.npy with mmap=r\n",
      "2024-04-21 12:17:50,432 - INFO - setting ignored attribute state to None\n",
      "2024-04-21 12:17:50,432 - INFO - setting ignored attribute dispatcher to None\n",
      "2024-04-21 12:17:50,433 - INFO - LdaModel lifecycle event {'fname': '/Users/joschka/Documents/0_Studium/0_ML_Master/0_current_lectures/NLP_practical_project/local_topical_summarization/data/LDA_250/lda.model', 'datetime': '2024-04-21T12:17:50.433167', 'gensim': '4.3.2', 'python': '3.11.7 (main, Dec 15 2023, 12:09:56) [Clang 14.0.6 ]', 'platform': 'macOS-14.4.1-arm64-arm-64bit', 'event': 'loaded'}\n",
      "2024-04-21 12:17:50,433 - WARNING - random_state not set so using default value\n",
      "2024-04-21 12:17:50,433 - INFO - dtype was not set in saved LdaModel file /Users/joschka/Documents/0_Studium/0_ML_Master/0_current_lectures/NLP_practical_project/local_topical_summarization/data/LDA_250/lda.model, assuming np.float64\n",
      "2024-04-21 12:17:50,433 - INFO - loading LdaState object from /Users/joschka/Documents/0_Studium/0_ML_Master/0_current_lectures/NLP_practical_project/local_topical_summarization/data/LDA_250/lda.model.state\n",
      "2024-04-21 12:17:50,434 - INFO - loading sstats from /Users/joschka/Documents/0_Studium/0_ML_Master/0_current_lectures/NLP_practical_project/local_topical_summarization/data/LDA_250/lda.model.state.sstats.npy with mmap=r\n",
      "2024-04-21 12:17:50,434 - INFO - LdaState lifecycle event {'fname': '/Users/joschka/Documents/0_Studium/0_ML_Master/0_current_lectures/NLP_practical_project/local_topical_summarization/data/LDA_250/lda.model.state', 'datetime': '2024-04-21T12:17:50.434568', 'gensim': '4.3.2', 'python': '3.11.7 (main, Dec 15 2023, 12:09:56) [Clang 14.0.6 ]', 'platform': 'macOS-14.4.1-arm64-arm-64bit', 'event': 'loaded'}\n",
      "2024-04-21 12:17:50,434 - INFO - dtype was not set in saved LdaState file /Users/joschka/Documents/0_Studium/0_ML_Master/0_current_lectures/NLP_practical_project/local_topical_summarization/data/LDA_250/lda.model.state, assuming np.float64\n",
      "2024-04-21 12:17:50,435 - INFO - Successfully loaded the LDA model.\n"
     ]
    }
   ],
   "source": [
    "lda = load_lda()\n",
    "# Warning \"WARNING:root:random_state not set so using default value\" is inconsequential for inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "HF_AUTH_TOKEN = \"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\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-2b-it\", token=HF_AUTH_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic words and tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOPIC_ID = 175\n",
    "N_TOPIC_WORDS = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['house', 'committee', 'congress', 'senate', 'republican', 'republicans', 'senator', 'rep', 'federal', 'democrats', 'sen', 'reid', 'chamber', 'democratic', 'capitol', 'government', 'congressional', 'lawmakers', 'gop', 'democrat', 'john', 'vets', 'chairman', 'members', 'reform']\n"
     ]
    }
   ],
   "source": [
    "topic_words = get_topic_words(lda=lda, tid=TOPIC_ID, num_topic_words=N_TOPIC_WORDS)\n",
    "print(topic_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[45568, 6666, 3600, 137748, 117272, 539, 65058, 84010, 32814, 45110, 63551, 7746, 582, 583, 37960, 6726, 19532, 3149, 25682, 66653, 172637, 607, 5733, 3688, 11368, 1642, 204396, 8304, 7792, 45174, 10871, 32376, 115327, 34945, 17032, 9866, 4757, 161944, 110232, 2721, 20645, 28839, 229546, 132778, 110765, 187383, 93877, 24249, 17598, 41153, 152257, 3778, 13512, 1738, 715, 82135, 16603, 3301, 119014, 45798, 744, 208108, 7405, 235248, 34545, 94453, 232185, 57082, 25338, 110331, 171772, 3838, 16636, 22271, 779, 1291, 49938, 66326, 3350, 155931, 200483, 1839, 53039, 235314, 819, 43316, 4919, 5431, 13625, 235319, 80700, 235330, 187718, 88905, 12622, 200531, 40275, 114014, 2912, 37223, 186732, 50036, 10109, 20864, 7562, 100235, 112523, 164748, 41357, 53136, 14231, 17818, 28572, 11677, 138660, 5549, 11708, 8639, 99777, 33734, 10694, 25040, 19409, 72144, 16340, 42970, 3036, 6111, 20960, 481, 482, 31203, 27618, 178150, 488, 6632, 207857, 36337, 12787, 100852, 5620, 71671, 107003, 175614]\n",
      "144\n",
      "Federal CongdemgopSenateid lawmakersVet john VetCommitteemak re g federJohn Members sen DemocraticFederdemocraticatesenmemberMember repcongress commitvetGovern federal democraticreformCommit reform Congress member HousChamberressionmembersMembersDemocrat capitol democratRepublicanschamber chairman Senate RepublicansReid members vetRepopSenator Feder Repfederal Capitol V Senat hous  Commitocratreidcommittee RepublicanDemocraticCapitol governmentCongLawansatorconggovern Johnchairman GopetsChairmanHous Reid House LawSenG congressionalV democratsCongress Governhous Reformvets lawGovernmentReform congress Federal chamber Committee senateRepublicanrepublic cong Democratcommit Chairmanitol committee vetscaprep govern republicangovernmentlaw ChamberHouse Congressionalmakerressional househousemakersanat Senatorjohn lawmakerte Government republicans Democrats Memberfeder Sen senatorocratsDemocrats\n"
     ]
    }
   ],
   "source": [
    "topic_tokens = get_topic_tokens(\n",
    "    lda=lda, tid=TOPIC_ID, num_topic_words=N_TOPIC_WORDS, tokenizer=tokenizer\n",
    ")\n",
    "print(topic_tokens)\n",
    "print(len(topic_tokens))\n",
    "# decode the tokens and print the result\n",
    "decoded_tokens = tokenizer.decode(topic_tokens, skip_special_tokens=False)\n",
    "print(decoded_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<bos>', '<eos>', '<unk>', '<pad>', '<start_of_turn>', '<end_of_turn>']\n",
      "[2, 1, 3, 0, 106, 107]\n"
     ]
    }
   ],
   "source": [
    "special_tokens = tokenizer.all_special_tokens\n",
    "special_ids = tokenizer.all_special_ids\n",
    "print(special_tokens)\n",
    "print(special_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108\n"
     ]
    }
   ],
   "source": [
    "# find out which token ID corresponds to '\\n'\n",
    "newline_token_id = tokenizer.convert_tokens_to_ids(\"\\n\")\n",
    "print(newline_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', '▁World', '▁Bank', '▁', '<eos>']\n",
      "[651, 3855, 6226, 235248, 1]\n",
      "The World Bank <eos>\n"
     ]
    }
   ],
   "source": [
    "text = \"The World Bank <eos>\"\n",
    "tokens = tokenizer.tokenize(text)\n",
    "print(tokens)\n",
    "token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "print(token_ids)\n",
    "print(tokenizer.decode(token_ids, skip_special_tokens=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_topic_tokens() got an unexpected keyword argument 'topic_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m topic_tokens \u001b[38;5;241m=\u001b[39m \u001b[43mget_topic_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlda\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlda\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtopic_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTOPIC_ID\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN_TOPIC_WORDS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(topic_tokens)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# decode the tokens and print the result\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: get_topic_tokens() got an unexpected keyword argument 'topic_id'"
     ]
    }
   ],
   "source": [
    "topic_tokens = get_topic_tokens(\n",
    "    lda=lda, topic_id=TOPIC_ID, num_words=N_TOPIC_WORDS, tokenizer=tokenizer\n",
    ")\n",
    "print(topic_tokens)\n",
    "# decode the tokens and print the result\n",
    "decoded_tokens = tokenizer.decode(topic_tokens, skip_special_tokens=False)\n",
    "print(decoded_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP_proj_basic_acc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

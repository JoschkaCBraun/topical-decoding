{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create topic strings\n",
    "For each topic create multiple strings that encode the topic well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.evaluation_utils import get_topic_words\n",
    "from utils.read_and_load_utils import load_lda\n",
    "from config import TOPICS_CONFIG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the LDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-16 11:36:06,594 - INFO - Data directory found at /Users/joschka/Documents/0_Studium/0_ML_Master/0_current/nlp_research_paper/topical-decoding/topical_decoding/data.\n",
      "2024-05-16 11:36:06,594 - INFO - loading LdaModel object from /Users/joschka/Documents/0_Studium/0_ML_Master/0_current/nlp_research_paper/topical-decoding/topical_decoding/data/LDA_250/lda.model\n",
      "2024-05-16 11:36:06,705 - INFO - loading id2word recursively from /Users/joschka/Documents/0_Studium/0_ML_Master/0_current/nlp_research_paper/topical-decoding/topical_decoding/data/LDA_250/lda.model.id2word.* with mmap=r\n",
      "2024-05-16 11:36:06,705 - INFO - loading expElogbeta from /Users/joschka/Documents/0_Studium/0_ML_Master/0_current/nlp_research_paper/topical-decoding/topical_decoding/data/LDA_250/lda.model.expElogbeta.npy with mmap=r\n",
      "2024-05-16 11:36:06,712 - INFO - setting ignored attribute state to None\n",
      "2024-05-16 11:36:06,712 - INFO - setting ignored attribute dispatcher to None\n",
      "2024-05-16 11:36:06,712 - INFO - LdaModel lifecycle event {'fname': '/Users/joschka/Documents/0_Studium/0_ML_Master/0_current/nlp_research_paper/topical-decoding/topical_decoding/data/LDA_250/lda.model', 'datetime': '2024-05-16T11:36:06.712800', 'gensim': '4.3.2', 'python': '3.11.7 (main, Dec 15 2023, 12:09:56) [Clang 14.0.6 ]', 'platform': 'macOS-14.4.1-arm64-arm-64bit', 'event': 'loaded'}\n",
      "2024-05-16 11:36:06,712 - WARNING - random_state not set so using default value\n",
      "2024-05-16 11:36:06,713 - INFO - dtype was not set in saved LdaModel file /Users/joschka/Documents/0_Studium/0_ML_Master/0_current/nlp_research_paper/topical-decoding/topical_decoding/data/LDA_250/lda.model, assuming np.float64\n",
      "2024-05-16 11:36:06,713 - INFO - loading LdaState object from /Users/joschka/Documents/0_Studium/0_ML_Master/0_current/nlp_research_paper/topical-decoding/topical_decoding/data/LDA_250/lda.model.state\n",
      "2024-05-16 11:36:06,714 - INFO - loading sstats from /Users/joschka/Documents/0_Studium/0_ML_Master/0_current/nlp_research_paper/topical-decoding/topical_decoding/data/LDA_250/lda.model.state.sstats.npy with mmap=r\n",
      "2024-05-16 11:36:06,714 - INFO - LdaState lifecycle event {'fname': '/Users/joschka/Documents/0_Studium/0_ML_Master/0_current/nlp_research_paper/topical-decoding/topical_decoding/data/LDA_250/lda.model.state', 'datetime': '2024-05-16T11:36:06.714951', 'gensim': '4.3.2', 'python': '3.11.7 (main, Dec 15 2023, 12:09:56) [Clang 14.0.6 ]', 'platform': 'macOS-14.4.1-arm64-arm-64bit', 'event': 'loaded'}\n",
      "2024-05-16 11:36:06,715 - INFO - dtype was not set in saved LdaState file /Users/joschka/Documents/0_Studium/0_ML_Master/0_current/nlp_research_paper/topical-decoding/topical_decoding/data/LDA_250/lda.model.state, assuming np.float64\n",
      "2024-05-16 11:36:06,715 - INFO - Successfully loaded the LDA model.\n"
     ]
    }
   ],
   "source": [
    "lda = load_lda()\n",
    "# Warning \"WARNING:root:random_state not set so using default value\" is inconsequential for inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the NEWTS dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-16 11:36:06,719 - INFO - Data directory found at /Users/joschka/Documents/0_Studium/0_ML_Master/0_current/nlp_research_paper/topical-decoding/topical_decoding/data.\n",
      "2024-05-16 11:36:06,789 - INFO - Successfully loaded NEWTS_train_2400 dataset.\n"
     ]
    }
   ],
   "source": [
    "from utils.read_and_load_utils import read_dataset\n",
    "\n",
    "# Load the NEWTS dataset\n",
    "newts_train = read_dataset(\"newts_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_idx</th>\n",
       "      <th>AssignmentId</th>\n",
       "      <th>docId</th>\n",
       "      <th>article</th>\n",
       "      <th>tid1</th>\n",
       "      <th>tid2</th>\n",
       "      <th>words1</th>\n",
       "      <th>words2</th>\n",
       "      <th>phrases1</th>\n",
       "      <th>phrases2</th>\n",
       "      <th>sentences1</th>\n",
       "      <th>sentences2</th>\n",
       "      <th>summary1</th>\n",
       "      <th>summary2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3EG49X351WE8VLP4S0TIYZF3V476X2</td>\n",
       "      <td>094372190d52acbce61a73ec16b2217d1a60276f</td>\n",
       "      <td>The president of the World Bank on Saturday wa...</td>\n",
       "      <td>175</td>\n",
       "      <td>110</td>\n",
       "      <td>house, committee, congress, senate, republican...</td>\n",
       "      <td>billion, figures, economy, global, growth, eco...</td>\n",
       "      <td>senate and congress, congressional pressure, y...</td>\n",
       "      <td>economic growth, global growth, billion dollar...</td>\n",
       "      <td>This topic is about the senate and congress, c...</td>\n",
       "      <td>This topic is about economic growth involving ...</td>\n",
       "      <td>The leader of the World Bank urged the US to t...</td>\n",
       "      <td>The US economy will be a driving factor in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3DOCMVPBTPGBQCHSPBSQ28AROFXNNI</td>\n",
       "      <td>bc733fb96fd73496e10fcff3c640ee11c4df3d7a</td>\n",
       "      <td>By . Nick Harris . Manchester City are the bes...</td>\n",
       "      <td>152</td>\n",
       "      <td>217</td>\n",
       "      <td>united, manchester, liverpool, chelsea, league...</td>\n",
       "      <td>club, team, season, players, england, football...</td>\n",
       "      <td>Manchester United's manager, Premier League, t...</td>\n",
       "      <td>football league, the team's fans, football pla...</td>\n",
       "      <td>This topic is about Manchester United's manage...</td>\n",
       "      <td>This topic is about a football league having a...</td>\n",
       "      <td>Premier league is the most paying football lea...</td>\n",
       "      <td>Manchester city players earn the largest amoun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3QHK8ZVMIOKJ13PAA872YL681IABLF</td>\n",
       "      <td>4ca225c38cc4a743e559efd586b99f162604ff16</td>\n",
       "      <td>Iran's military on Sunday claimed it shot down...</td>\n",
       "      <td>64</td>\n",
       "      <td>134</td>\n",
       "      <td>group, forces, fighters, killed, fighting, mil...</td>\n",
       "      <td>air, plane, aircraft, flight, flying, pilot, f...</td>\n",
       "      <td>group composed of militants, fighters joining ...</td>\n",
       "      <td>flying the plane, the pilot of this aircraft, ...</td>\n",
       "      <td>This topic is about a group composed of milita...</td>\n",
       "      <td>This topic is about flying the plane, the pilo...</td>\n",
       "      <td>Iran's military claimed it shot down a U.S. dr...</td>\n",
       "      <td>Iran's military claims shooting down an Americ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_idx                    AssignmentId  \\\n",
       "0            0  3EG49X351WE8VLP4S0TIYZF3V476X2   \n",
       "1            1  3DOCMVPBTPGBQCHSPBSQ28AROFXNNI   \n",
       "2            2  3QHK8ZVMIOKJ13PAA872YL681IABLF   \n",
       "\n",
       "                                      docId  \\\n",
       "0  094372190d52acbce61a73ec16b2217d1a60276f   \n",
       "1  bc733fb96fd73496e10fcff3c640ee11c4df3d7a   \n",
       "2  4ca225c38cc4a743e559efd586b99f162604ff16   \n",
       "\n",
       "                                             article  tid1  tid2  \\\n",
       "0  The president of the World Bank on Saturday wa...   175   110   \n",
       "1  By . Nick Harris . Manchester City are the bes...   152   217   \n",
       "2  Iran's military on Sunday claimed it shot down...    64   134   \n",
       "\n",
       "                                              words1  \\\n",
       "0  house, committee, congress, senate, republican...   \n",
       "1  united, manchester, liverpool, chelsea, league...   \n",
       "2  group, forces, fighters, killed, fighting, mil...   \n",
       "\n",
       "                                              words2  \\\n",
       "0  billion, figures, economy, global, growth, eco...   \n",
       "1  club, team, season, players, england, football...   \n",
       "2  air, plane, aircraft, flight, flying, pilot, f...   \n",
       "\n",
       "                                            phrases1  \\\n",
       "0  senate and congress, congressional pressure, y...   \n",
       "1  Manchester United's manager, Premier League, t...   \n",
       "2  group composed of militants, fighters joining ...   \n",
       "\n",
       "                                            phrases2  \\\n",
       "0  economic growth, global growth, billion dollar...   \n",
       "1  football league, the team's fans, football pla...   \n",
       "2  flying the plane, the pilot of this aircraft, ...   \n",
       "\n",
       "                                          sentences1  \\\n",
       "0  This topic is about the senate and congress, c...   \n",
       "1  This topic is about Manchester United's manage...   \n",
       "2  This topic is about a group composed of milita...   \n",
       "\n",
       "                                          sentences2  \\\n",
       "0  This topic is about economic growth involving ...   \n",
       "1  This topic is about a football league having a...   \n",
       "2  This topic is about flying the plane, the pilo...   \n",
       "\n",
       "                                            summary1  \\\n",
       "0  The leader of the World Bank urged the US to t...   \n",
       "1  Premier league is the most paying football lea...   \n",
       "2  Iran's military claimed it shot down a U.S. dr...   \n",
       "\n",
       "                                            summary2  \n",
       "0  The US economy will be a driving factor in the...  \n",
       "1  Manchester city players earn the largest amoun...  \n",
       "2  Iran's military claims shooting down an Americ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newts_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"senate and congress, congressional pressure, you can call your representative's office, told a Senate committee, lawmakers setting the record straight, staffer to the Democratic senator, federal employee benefits\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newts_train['phrases1'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"This topic is about the senate and congress, congressional pressure, calling one's representative's office, informing a Senate committee, lawmakers setting the record straight, the staffer to the Democratic senator, and federal employee benefits.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newts_train['sentences1'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of different topics in the dataset:  50\n",
      "Topic IDs:  {12, 13, 32, 39, 46, 48, 55, 61, 62, 64, 72, 78, 83, 85, 89, 90, 97, 100, 101, 105, 110, 113, 115, 128, 129, 134, 144, 152, 153, 162, 163, 175, 180, 187, 194, 195, 196, 198, 199, 200, 205, 211, 217, 218, 227, 229, 236, 245, 247, 248}\n"
     ]
    }
   ],
   "source": [
    "# number of different topics (tid1 or tid2) in the dataset\n",
    "relevant_tids = set(map(int, newts_train['tid1'].unique())).union(set(map(int, newts_train['tid2'].unique())))\n",
    "print(\"Number of different topics in the dataset: \", len(relevant_tids))\n",
    "print(\"Topic IDs: \", relevant_tids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting topic strings\n",
    "For each of the 50 topics that appead in the NEWTS train dataset, create topic strings.\n",
    "As a datastructure we use a dictionary and use the relevant_tids as the keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_strings = dict()\n",
    "for tid in relevant_tids:\n",
    "    topic_strings[tid] = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic string: topic words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topic_words = TOPICS_CONFIG['num_topic_words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tid in relevant_tids:\n",
    "    topic_words = get_topic_words(lda=lda, tid=tid, num_topic_words=num_topic_words)\n",
    "    # concatenate the words into a single string\n",
    "    topic_strings[tid]['topic_words'] = \" \".join(topic_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of topic words for topic 175:  house committee congress senate republican republicans senator rep federal democrats sen reid chamber democratic capitol government congressional lawmakers gop democrat john vets chairman members reform\n"
     ]
    }
   ],
   "source": [
    "print(\"Example of topic words for topic 175: \", topic_strings[175]['topic_words'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic string: topic phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# while not all relevant_tids have been seen, iterate over the dataset and use the phrases as topic_strings[tid][topic_phrases]\n",
    "missing_tids = set(relevant_tids)\n",
    "for index, row in newts_train.iterrows():\n",
    "    tid1 = row['tid1']\n",
    "    tid2 = row['tid2']\n",
    "    if tid1 in missing_tids:\n",
    "        topic_strings[tid1]['topic_phrases'] = row['phrases1']\n",
    "        missing_tids.remove(tid1)\n",
    "    if tid2 in missing_tids:\n",
    "        topic_strings[tid2]['topic_phrases'] = row['phrases2']\n",
    "        missing_tids.remove(tid2)\n",
    "    if len(missing_tids) == 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of topic phrases for topic 175:  senate and congress, congressional pressure, you can call your representative's office, told a Senate committee, lawmakers setting the record straight, staffer to the Democratic senator, federal employee benefits\n"
     ]
    }
   ],
   "source": [
    "print(\"Example of topic phrases for topic 175: \", topic_strings[175]['topic_phrases'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic string: topic description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# while not all relevant_tids have been seen, iterate over the dataset and use the sentences as topic_strings[tid][topic_description]\n",
    "missing_tids = set(relevant_tids)\n",
    "for index, row in newts_train.iterrows():\n",
    "    tid1 = row['tid1']\n",
    "    tid2 = row['tid2']\n",
    "    if tid1 in missing_tids:\n",
    "        topic_strings[tid1]['topic_description'] = row['sentences1']\n",
    "        missing_tids.remove(tid1)\n",
    "    if tid2 in missing_tids:\n",
    "        topic_strings[tid2]['topic_description'] = row['sentences2']\n",
    "        missing_tids.remove(tid2)\n",
    "    if len(missing_tids) == 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of topic description for topic 175:  This topic is about the senate and congress, congressional pressure, calling one's representative's office, informing a Senate committee, lawmakers setting the record straight, the staffer to the Democratic senator, and federal employee benefits.\n"
     ]
    }
   ],
   "source": [
    "print(\"Example of topic description for topic 175: \", topic_strings[175]['topic_description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the topic strings to a file under the data folder in the topic_vectors_data folder\n",
    "# the data folder is two levels up from the current folder\n",
    "import os\n",
    "import json\n",
    "\n",
    "with open('../../data/topic_vectors_data/topic_strings.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(topic_strings, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use topic focussed summaries to generate topic vectors\n",
    "Instead of using direct descriptions of the topic, use the summaries that focus on the topic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of summaries that focus on each topic:  {12: 49, 13: 70, 32: 75, 39: 158, 46: 87, 48: 106, 55: 74, 61: 116, 62: 69, 64: 94, 72: 56, 78: 82, 83: 76, 85: 56, 89: 73, 90: 26, 97: 44, 100: 62, 101: 41, 105: 167, 110: 109, 113: 135, 115: 191, 128: 135, 129: 60, 134: 129, 144: 133, 152: 110, 153: 65, 162: 217, 163: 89, 175: 92, 180: 83, 187: 85, 194: 107, 195: 182, 196: 94, 198: 69, 199: 55, 200: 107, 205: 35, 211: 76, 217: 201, 218: 97, 227: 48, 229: 55, 236: 95, 245: 75, 247: 187, 248: 103}\n",
      "Min and max number of summaries that focus on a topic:  26 217\n"
     ]
    }
   ],
   "source": [
    "# for each relevant tid, count the number of summaries that focus on that topic. \n",
    "# Use the tid1 and tid2 columns to count the number of summaries that focus on that topic.\n",
    "topic_counts = dict()\n",
    "for tid in relevant_tids:\n",
    "    topic_counts[tid] = 0\n",
    "\n",
    "for index, row in newts_train.iterrows():\n",
    "    tid1 = row['tid1']\n",
    "    tid2 = row['tid2']\n",
    "    topic_counts[tid1] += 1\n",
    "    topic_counts[tid2] += 1\n",
    "\n",
    "print(\"Number of summaries that focus on each topic: \", topic_counts)\n",
    "print(\"Min and max number of summaries that focus on a topic: \", min(topic_counts.values()), max(topic_counts.values()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP_proj_basic_acc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
